### Ch1 并发编程初探
#### Java 天生多线程
在一个进程里可以创建多个线程，这些线程都拥有各自的计数器、堆栈和局部变量等属性，并且能够访问共享的内存变量。处理器在这些线程上高速切换，让使用者感觉到这些线程在同时执行。

当前的main函数就是一个 JVM 进程。 打印出来的 6 条线程信息就是进程中的多条线程。
```java
import java.lang.management.ManagementFactory;
import java.lang.management.ThreadInfo;
import java.lang.management.ThreadMXBean;

public class ThreadPrint {

	public static void main(String[] args) throws InterruptedException {

// 获取Java线程管理MXBean

		ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();

// 不需要获取同步的monitor和synchronizer信息，仅获取线程和线程堆栈信息

		ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false);

// 遍历线程信息，仅打印线程ID和线程名称信息

		for (ThreadInfo threadInfo : threadInfos) {

			System.out.println("[" + threadInfo.getThreadId() + "] " + threadInfo.getThreadName());

		}

		Thread.sleep(1000000); jps jstack

	}

}

```

[1] main 主线程
[2] Reference Handler 引用处理线程 
   ： [强，软，弱，虚](https://blog.csdn.net/jiangxiulilinux/article/details/105391516). gc 时候有不同的表现 ---jvm 深入分析
[3] Finalizer： JVM 垃圾回收相关内容
	1. 只有当开始一轮垃圾收集的时候，才会开始调用finalize方法
	2. daemon prio=10 高优先级的守护线程
	3. jvm在垃圾收集的时候，会将**失去引用**的对象封装到我们的 Fianlizer 对象（Reference）， 放入我们的 F-queue 队列中。由 Finalizer 线程执行Finalize方法
[4] Signal Dispatcher: 信号分发
	我们通过cmd 发送jstack，传到了jvm进程，这时候信号分发器就要发挥作用
[5] Attach Listener: 附加监听器
	简单来说，他是jdk里边一个工具类提供的**jvm** **进程之间通信**的工具。 
	java -version; jvm -- jstack、jmap、dump） 进程间的通信。
	开启我们这个线程的两个方式
	1. 通过jvm参数开启。-XX: StartAttachListener
	2. 延迟开启： cmd -- java -version --> JVM 适时开启A L 线程
[10] Common-Cleaner
```
"Monitor Ctrl-Break" #6 daemon prio=5 os_prio=0 tid=0x000000001a932800 nid=0x3bf8 runnable [0x000000001b96e000]

java.lang.Thread.State: RUNNABLE

at java.net.SocketInputStream.socketRead0(Native Method)

at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)

at java.net.SocketInputStream.read(SocketInputStream.java:170)

at java.net.SocketInputStream.read(SocketInputStream.java:141)

at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)

at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)

at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)

- locked <0x00000000d67070b8> (a java.io.InputStreamReader)

at java.io.InputStreamReader.read(InputStreamReader.java:184)

at java.io.BufferedReader.fill(BufferedReader.java:161)

at java.io.BufferedReader.readLine(BufferedReader.java:324)

- locked <0x00000000d67070b8> (a java.io.InputStreamReader)

at java.io.BufferedReader.readLine(BufferedReader.java:389)

at com.intellij.rt.execution.application.AppMainV2$1.run(AppMainV2.java:64)

  

"Attach Listener" #5 daemon prio=5 os_prio=2 tid=0x0000000019a39000 nid=0x283c waiting on condition [0x0000000000000000] prio=5 延迟开启的问题。

java.lang.Thread.State: RUNNABLE

  

"Signal Dispatcher" #4 daemon prio=9 os_prio=2 tid=0x0000000019a38800 nid=0x1dd4 runnable [0x0000000000000000]

java.lang.Thread.State: RUNNABLE

  

"Finalizer" #3 daemon prio=8 os_prio=1 tid=0x0000000017ae8800 nid=0x3708 in Object.wait() [0x0000000019e9f000] （Finalizer 专注垃圾收集，垃圾收集 -- 并行收集，不阻碍用户线程，低优先级线程。 prio=8 他是一个守护线程啊。而且这个线程目前并没有真正的开启，不足以发生minorgc或者是 full gc、）

java.lang.Thread.State: **WAITING (on object monitor)**

at java.lang.Object.wait(Native Method)

- waiting on <0x00000000d6108e98> (a java.lang.ref.ReferenceQueue$Lock)

at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)

- locked <0x00000000d6108e98> (a java.lang.ref.ReferenceQueue$Lock)

at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)

at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

  

"Reference Handler" #2 daemon prio=10 os_prio=2 tid=0x0000000017ae1800 nid=0x1ee0 in Object.wait() [0x000000001999f000] （引用处理线程-GC相关线程：GC 很重要啊，优先级还挺高）

java.lang.Thread.State: WAITING (on object monitor)

at java.lang.Object.wait(Native Method)

- waiting on <0x00000000d6106b40> (a java.lang.ref.Reference$Lock)

at java.lang.Object.wait(Object.java:502)

at java.lang.ref.Reference.tryHandlePending(Reference.java:191)

- locked <0x00000000d6106b40> (a java.lang.ref.Reference$Lock)

at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)

  

"main" #1 prio=5 os_prio=0 tid=0x00000000028f4800 nid=0x25ac waiting on condition [0x00000000028ef000] （操作系统面向的是JVM 进程，JVM 进程里面向的是 我们的main函数，。所以对于我们的操作系统如何看待我们的main函数优先级，无所谓。 只要os 给我们jvm进程足够公平的优先级就行。）

java.lang.Thread.State: TIMED_WAITING (sleeping)

at java.lang.Thread.sleep(Native Method)

at com.boot.jdk.ThreadPrint.main(ThreadPrint.java:20)
```


#### 线程的优先级
在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配CPU时间片的数量要多于优先级低的线程。
**设置线程优先级时，针对频繁阻塞（休眠或者I/O操作）的线程需要设置较高优先级，而偏重计算（需要较多CPU时间或者偏运算）的线程则设置较低的优先级，确保处理器不会被独占。

```java
public class ThreadPrority {

	public static void main(String[] args){

		System.out.println(Thread.currentThread().getName()+"("+Thread.currentThread().getPriority()+ ")");
		
		Thread t1=new MyThread("t1"); // 新建t1
		Thread t2=new MyThread("t2"); // 新建t2
		t1.setPriority(1); // 设置t1的优先级为1
		t2.setPriority(10); // 设置t2的优先级为10
		t1.start(); // 启动t1
		t2.start(); // 启动t2
	}

}

class MyThread extends Thread{

	public MyThread(String name) {
		super(name);
	}
	public void run(){
	
		for (int i=0; i<5; i++) {
			System.out.println(
			Thread.currentThread().getName()+"("+
			Thread.currentThread().getPriority()+ ")"+", loop "+i);
	}

// Thread.sleep(100000); 

	}

};
```
结果五花八门，setPriority 没有绝对的作用
setPriority 这个方法，他是 jvm 提供的一个方法，并且能够调用 本地方法setPriority0. 我们发现优先级貌似没有起作用，
为什么？ 
	1. 我们现在的计算机都是多核的，t1，t2 会让哪个cpu处理不好说。由不同的cpu同时提供资源执行。
	2. 优先级不代表先后顺序。哪怕你的优先级低，也是有可能先拿到我们的cpu时间片的，只不过这个时间片比高优先级的线程的时间片短。 **优先级针对的是 cpu时间片的长短问题**。 
	3. 目前工作中，实际项目里，**不必要**使用setPriority方法。我们现在都是用 hystrix， sential也好，一些开源的信号量控制工具，都能够实现线程资源的合理调度。这个 setPriority方法，很难控制。实际的运行环境太复杂。
```java
public final void setPriority(int newPriority) {
	ThreadGroup g; // main 线程
	checkAccess(); // 确保当前线程有权限访问。
	if (newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY) {
		throw new IllegalArgumentException();
	} // 1 到 10 之间

	if((g = getThreadGroup()) != null) {
		if (newPriority > g.getMaxPdriority()) {
			newPriority = g.getMaxPriority();
		} //线程组中最大线程： 都是10 除非设置
	setPriority0(priority = newPriority);// 本地方法

	}
}

public final void checkAccess() {
	SecurityManager security = System.getSecurityManager();

	if (security != null) {
		security.checkAccess(this);
	}

}

```
 ### 守护线程
Daemon线程是一种支持型线程，因为它**主要被用作程序中后台调度以及支持性工作**。这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调 用Thread.setDaemon(true)将线程设置为Daemon线程。
```java
public class ThreadDaemon {
	public static void main(String[] args) {
		Thread thread = new Thread(new DaemonThread(),"Daemon Thread!");
		thread.setDaemon(true); // 守护线程
		thread.start();
		// main 线程退出
	}

	static class DaemonThread implements Runnable {
		@Override
		public void run() {
			try {
				Thread.sleep(5000);
			} catch (InterruptedException e) {
				e.printStackTrace();
			} finally { //finally 不能够保证我们的守护线程的最终执行
				System.out.println("FINISH!");
			}
		}
	}

}
```

```java
public final void setDaemon(boolean on) {
	checkAccess();

	if (isAlive()) {
		throw new IllegalThreadStateException();
		// 告诉我们，必须要先设置线程是否为守护线程，然后再调用start方法。如果你先调用start
	}
	daemon = on;
}
```

#### 线程状态的转换
```java
public class ReadStackLog {
	public static void main(String[] args) throws JsonProcessingException {
	new Thread(new TimeWaiting (), "TimeWaitingThread").start();
	new Thread(new Waiting(), "WaitingThread").start();
	// 使用两个Blocked线程，一个获取锁成功，另一个被阻塞
	new Thread(new Blocked(), "BlockedThread-1").start();
	new Thread(new Blocked(), "BlockedThread-2").start();
	}
}
// 该线程不断地进行睡眠
class TimeWaiting implements Runnable {
	@SneakyThrows
	@Override
	public void run() {
		while (true) {
			Thread.sleep(1000000);
		}
	}
}
// 该线程在Waiting.class实例上等待
class Waiting implements Runnable {
@Override
	public void run() {
		while (true) {
			synchronized (Waiting.class) {
				try {
					Waiting.class.wait();
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
			}
		}
	}

}
// 该线程在Blocked.class实例上加锁后，不会释放该锁
class Blocked implements Runnable {
@SneakyThrows
	public void run() {
		synchronized (Blocked.class) {
			while (true) {
				Thread.sleep(1000000);
			}
		}
	}
}
```

```
"BlockedThread-2" #15 prio=5 os_prio=0 tid=0x000000001b956000 nid=0x22d8 waiting for monitor entry [0x000000001d0be000](发现死锁，一直不会释放的话)

	java.lang.Thread.State: BLOCKED (on object monitor)
	at com.boot.jdk.Blocked.run(ReadStackLog.java:45)
		- waiting to lock <0x00000000d67bca20> (a java.lang.Class for com.boot.jdk.Blocked)
	at java.lang.Thread.run(Thread.java:745)

"BlockedThread-1" #14 prio=5 os_prio=0 tid=0x000000001b955000 nid=0x4c4c waiting on condition [0x000000001cfbf000]
	java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at com.boot.jdk.Blocked.run(ReadStackLog.java:45)
		- locked <0x00000000d67bca20> (a java.lang.Class for com.boot.jdk.Blocked)
	at java.lang.Thread.run(Thread.java:745)

// 一个block 一个 sleeping

"WaitingThread" #13 prio=5 os_prio=0 tid=0x000000001b954800 nid=0x39cc in Object.wait() [0x000000001cebf000]
	java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
		- waiting on <0x00000000d67ba680> (a java.lang.Class for com.boot.jdk.Waiting)
	at java.lang.Object.wait(Object.java:502)
	at com.boot.jdk.Waiting.run(ReadStackLog.java:31)
		- locked <0x00000000d67ba680> (a java.lang.Class for com.boot.jdk.Waiting)
	at java.lang.Thread.run(Thread.java:745)


"TimeWaitingThread" #12 prio=5 os_prio=0 tid=0x000000001b951800 nid=0x3820 waiting on condition [0x000000001cdbe000]
	java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at com.boot.jdk.TimeWaiting.run(ReadStackLog.java:20)
	at java.lang.Thread.run(Thread.java:745)


"Attach Listener" #5 daemon prio=5 os_prio=2 tid=0x000000001a72b000 nid=0x4ea8 waiting on condition [0x0000000000000000]
	java.lang.Thread.State: RUNNABLE


"Signal Dispatcher" #4 daemon prio=9 os_prio=2 tid=0x000000001a6d2800 nid=0x3d94 runnable [0x0000000000000000]
	java.lang.Thread.State: RUNNABLE


"Finalizer" #3 daemon prio=8 os_prio=1 tid=0x000000001a6b1800 nid=0x4254 in Object.wait() [0x000000001ab8f000] （只有进行垃圾收集的时候，才会被notify。 用到我们的 signal Dispatcher）
	java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
		- waiting on <0x00000000d6108e98> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)
		- locked <0x00000000d6108e98> (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)
	at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209)

"Reference Handler" #2 daemon prio=10 os_prio=2 tid=0x00000000187c1000 nid=0x48a8 in Object.wait() [0x000000001a68f000] （引用处理线程。）Thread.start 之后，他会进入一个就绪状态，还没有分配到 cpu的执行权。 当cpu的时间片切换到他的时候，他才会开始执行，进入running状态
	java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
		- waiting on <0x00000000d6106b40> (a java.lang.ref.Reference$Lock)
	at java.lang.Object.wait(Object.java:502)
	at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
		- locked <0x00000000d6106b40> (a java.lang.ref.Reference$Lock)
	at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
	
```
<img src="https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220625180955.png"/>
#### 代码分析
```java
public enum State {
NEW,
RUNNABLE,
BLOCKED,
// monitor lock only on synchronized have the block state
WAITING,
	// {@link Object#wait() Object.wait} with no timeout</li>
	// {@link #join() Thread.join} with no timeout</li>
	// {@link LockSupport#park() LockSupport.park}</li>
TIMED_WAITING,
	/**
	{@link #sleep Thread.sleep}
	{@link Object#wait(long) Object.wait} with timeout
	{@link #join(long) Thread.join} with timeout
	{@link LockSupport#parkNanos LockSupport.parkNanos}
	{@link LockSupport#parkUntil LockSupport.parkUntil}
	*/
TERMINATED;
// 六种 但是博客说的七种是在runable下面的划分：通过cpu执行权 running
}
// Thread.join 他底层代码调用的是 Object的 wait方法（后边会带大家看 join方法的jdk源码）。那么想要唤醒join方法，就需要使用 object的notify以及 notifyall

```
#### 线程的初始化
##### init
一个新构造的线程对象是由其parent线程来进行空间分配的，而child线程继承了parent是否为Daemon、优先级和加载资源的contextClassLoader以及可继承的ThreadLocal，同时还会分配一个唯一的（sync）ID来标识这个child线程。至此，一个能够运行的线程对象就初始化好了，在堆内存中等待着运行。
1. 尊重线程初始化穿入的threadgroup 次选System security mananger 的 tg；再次选 parent的 tg。
2. NEW状态的线程，会添加到threadGroup。
3. 新的线程的属性依赖于 父类线程。
```java
private Thread(ThreadGroup g, Runnable target, String name,
		long stackSize, AccessControlContext acc,
		boolean inheritThreadLocals) {
	if (name == null) {
		throw new NullPointerException("name cannot be null");
	}
	
	this.name = name;
	
	Thread parent = currentThread();
	
	SecurityManager security = System.getSecurityManager();
	if (g == null) {
		/* Determine if it's an applet or not */
		/* If there is a security manager, ask the security manager
		what to do. */
		if (security != null) {
			g = security.getThreadGroup();
		}
		/* If the security manager doesn't have a strong opinion
		on the matter, use the parent thread group. */
		if (g == null) {
			g = parent.getThreadGroup();
		}
	}
	
	
	/* checkAccess regardless of whether or not threadgroup is
	explicitly passed in. */
	g.checkAccess();
	
	/*
	* Do we have the required permissions?
	*/
	
	if (security != null) {
		if (isCCLOverridden(getClass())) {
			security.checkPermission(
			SecurityConstants.SUBCLASS_IMPLEMENTATION_PERMISSION);
		}
	}
	// NEW状态的线程，会添加到threadGroup。
	g.addUnstarted();
	// 新的线程的属性依赖于 父类线程。
	this.group = g;
	this.daemon = parent.isDaemon();
	this.priority = parent.getPriority();
	if (security == null || isCCLOverridden(parent.getClass()))
		this.contextClassLoader = parent.getContextClassLoader();
	else
		this.contextClassLoader = parent.contextClassLoader;
	
	this.inheritedAccessControlContext =
	acc != null ? acc : AccessController.getContext();
	
	this.target = target;
	
	setPriority(priority);
	
	if (inheritThreadLocals && parent.inheritableThreadLocals != null)
		this.inheritableThreadLocals = 
		ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
	/* Stash the specified stack size in case the VM cares */
	this.stackSize = stackSize;
	
	/* Set thread ID */
	this.tid = nextThreadID();

}


private static synchronized long nextThreadID() {  
	return ++threadSeqNumber;  
}

//保证我们的tid的唯一性。
```
#### start
线程对象在初始化完成之后，调用start()方法就可以启动这个线程。线程start()方法的含义是：当前线程（即parent线程）同步告知Java虚拟机，只要线程规划器空闲，应立即启动调用start()方法的线程。
1. 避免多线程同时启动一个线程。IllegalThreadStateException
2. start0 完全执行完之前，线程处于 Ready
3. 完成后，只要cpu分配执行权，我们的线程就进入了Running状态。
4. _Start0_ _这个异常，会直接反馈给我们的调用线程。Main函数里边的_ thread.start方法。 **防止我们的thread.start方法感知不到异常**，导致程序的错误的继续执行。
```java
private volatile int threadStatus; // 二次确保不会同时进行
public synchronized void start() {
	/**
	* This method is not invoked for the main method thread or "system"
	* group threads created/set up by the VM. Any new functionality added
	* to this method in the future may have to also be added to the VM.
	* A zero status value corresponds to state "NEW".
	*/
	if (threadStatus != 0)
		throw new IllegalThreadStateException();
	/* Notify the group that this thread is about to be started
	* so that it can be added to the group's list of threads
	* and the group's unstarted count can be decremented. */
	group.add(this);
	boolean started = false;
	try {
		start0();
		started = true;
	} finally {
		try {
			if (!started) {
				group.threadStartFailed(this);
			}
		} catch (Throwable ignore) {
			/* do nothing. If start0 threw a Throwable then
			it will be passed up the call stack */
		}
	}

}
```
#### sleep
1. 是否释放锁：否
2. 是否对中断敏感： 是
3. 是否释放CPU： 是
```java
/**
* Causes the currently executing thread to sleep (temporarily cease
* execution) for the specified number of milliseconds plus the specified
* number of nanoseconds, subject to the precision and accuracy of system
* timers and schedulers. The thread does not lose ownership of any
* monitors.
*/
public static native void sleep(long millis) throws InterruptedException
```
#### Wait
1. 是否释放锁：是
2. 是否对中断敏感： 是
3. 是否释放CPU： 是
	让出 CPU 时间片。进入等待队列。（sync时候，深入介绍。waitset， _cxq, entrylist）


#### Join
释放的是当前调用 join方法的那个对象的锁。普通方法
1. 是否释放锁：具体要看当前的锁对象是谁。如果是调用join方法的锁对象，则释放。
2. 是否对中断敏感： 是
3. 是否释放CPU： 是 底层调用的wait()
```java
public final synchronized void join(final long millis)
throws InterruptedException {
	if (millis > 0) {
		if (isAlive()) {
			final long startTime = System.nanoTime();
			long delay = millis;
		do {
			wait(delay);
		} while (isAlive() && (delay = millis -
			TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime)) > 0);
	}
	} else if (millis == 0) {
		while (isAlive()) {
		wait(0); 
		// 这个wait是调用的Object的，但是这是父类。其实这个wait方法前边有一个隐含的意义： this.wait(不是很准确)--》 当前的线程类（Thread类--有一个当前的线程）。 其实目前来看，这个是当前线程释放了cpu，而且是当前线程（Thread类）这个对象释放了锁。.
	}
	} else {
		throw new IllegalArgumentException("timeout value is negative");
	}

}
```

#### 线程之间的通信方式
1. volitate 、synchronize、lock。（都保证可见性）
2. wait、notify、await() 、 signal
3. 管道输入、输出流  (示例代码：PipeInOut.java)
	  管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要用于**线程之间的数据传输，而传输的媒介为内存。**
	管道输入/输出流主要包括了如下4种具体实现：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter，前两种面向字节，而后两种面向字符。
4. Thread.join() ： 隐式唤醒。等待其他线程执行完成，其他线程会发送唤醒信号。
5. ThradLocal() ---》支持子线程集成的一种形式。埋点。
6. 线程中断
```java
public class PipeInOut {
    public static void main(String[] args) throws IOException {
        PipedWriter out = new PipedWriter();
        PipedReader in = new PipedReader();
        // 将输出流和输入流进行连接，否则在使用时会抛出IOException
        out.connect(in);
        Thread printThread = new Thread(new Print(in), "PrintThread");
        printThread.start();
        int receive = 0;
        try {
            while ((receive = System.in.read()) != -1) {
                out.write(receive);
            }
        } finally {
            out.close();
        }
    }
    static class Print implements Runnable {
        private PipedReader in;
        public Print(PipedReader in) {
            this.in = in;
        }
        public void run() {
            int receive = 0;
            try {
                while ((receive = in.read()) != -1) {
                    System.out.print((char) receive);
                }
            } catch (IOException ex) {
            }
        }
    }
}
```
1. sleep is interrupted : false 因为先清除标志位，后抛出异常
```java
public class ThreadInterrupted {
    public static void main(String[] args) throws InterruptedException {
        // sleepThread不停的尝试睡眠
        Thread sleepThread = new Thread(new SleepRunner(), "SleepThread");
        sleepThread.setDaemon(true);
        Thread busyThread = new Thread(new BusyRunner(), "BusyThread");
        busyThread.setDaemon(true);
        sleepThread.start();
        busyThread.start();
        // 休眠5秒，让sleepThread和busyThread充分运行
        TimeUnit.SECONDS.sleep(5);
        sleepThread.interrupt();
        busyThread.interrupt();
        //sleep方法应中断，肯定会中断sleep。在抛出异常之前，会清理掉我们的 中断标志。 会返回false，因为当前线程已经停止了。
        System.out.println("SleepThread interrupted is " + sleepThread.isInterrupted());
  
       // busy thread ,没有立即响应中断，知识他的中断标志位 显示 被中断，这个是isInterrupted会返回true。
        System.out.println("BusyThread interrupted is " + busyThread.isInterrupted());
        // 防止sleepThread和busyThread立刻退出
        TimeUnit.SECONDS.sleep(5);
    }
  
    static class SleepRunner implements Runnable {
        @SneakyThrows
        @Override
        public void run() {
            while (true) {
                try {
                    // 先清除标志，后抛异常、（sleep）
                    TimeUnit.SECONDS.sleep(100);
                } catch (Exception e) {
                    System.out.println("======");
                }
            }
        }
    }
    static class BusyRunner implements Runnable {
        @Override
        public void run() {
            while (true) {
            }
        }
    }
}

```
### Ch2 synchronized 全解读
#### synchronized 的使用 javap -v 深入查看
1. 普通方法: 锁对象 我们的对象（new 出来的，谁调用这个方法，锁作用于谁身上）
2. 静态方法: 锁对象：我们的对象所属的class，全局只有一个。（类型，放到方法区的包括我们的真正的.class文件的二进制文件都最终加载到了运行时数据区的方法区）
3. 同步代码块： 
```java
public class SyncUsingWay {
    public synchronized void SyncMethod() {
        System.out.println("SyncMethod");
    }
    public synchronized static void StaticSyncMethod(){
        System.out.println("StaticSyncMethod");
    }
    public void method(){
        // 静态代码块
        synchronized (this) {
            System.out.println("method");
        }
    }
}
```
```text
Classfile /E:/IdeaWorkspace/demo/target/classes/com/boot/jdk/SyncUsingWay.class
  Last modified 2022-5-8; size 917 bytes
  MD5 checksum 9a53c6cd6851b0895ead00ce639fde81
  Compiled from "SyncUsingWay.java"
public class com.boot.jdk.SyncUsingWay
  minor version: 0
  major version: 52
  flags: ACC_PUBLIC, ACC_SUPER
Constant pool
   #1 = Methodref          #8.#30         // java/lang/Object."<init>":()V
   #2 = Fieldref           #31.#32        // java/lang/System.out:Ljava/io/PrintStream;
   #3 = String             #16            // SyncMethod
   #4 = Methodref          #33.#34        // java/io/PrintStream.println:(Ljava/lang/String;)V
   #5 = String             #17            // StaticSyncMethod
   #6 = String             #18            // method
   #7 = Class              #35            // com/boot/jdk/SyncUsingWay
   #8 = Class              #36            // java/lang/Object
   #9 = Utf8               <init>
  #10 = Utf8               ()V
  #11 = Utf8               Code
  #12 = Utf8               LineNumberTable
  #13 = Utf8               LocalVariableTable
  #14 = Utf8               this
  #15 = Utf8               Lcom/boot/jdk/SyncUsingWay;
  #16 = Utf8               SyncMethod
  #17 = Utf8               StaticSyncMethod
  #18 = Utf8               method
  #19 = Utf8               StackMapTable
  #20 = Class              #35            // com/boot/jdk/SyncUsingWay
  #21 = Class              #36            // java/lang/Object
  #22 = Class              #37            // java/lang/Throwable
  #23 = Utf8               main
  #24 = Utf8               ([Ljava/lang/String;)V
  #25 = Utf8               args
  #26 = Utf8               [Ljava/lang/String;
  #27 = Utf8               MethodParameters
  #28 = Utf8               SourceFile
  #29 = Utf8               SyncUsingWay.java
  #30 = NameAndType        #9:#10         // "<init>":()V
  #31 = Class              #38            // java/lang/System
  #32 = NameAndType        #39:#40        // out:Ljava/io/PrintStream;
  #33 = Class              #41            // java/io/PrintStream
  #34 = NameAndType        #42:#43        // println:(Ljava/lang/String;)V
  #35 = Utf8               com/boot/jdk/SyncUsingWay
  #36 = Utf8               java/lang/Object
  #37 = Utf8               java/lang/Throwable
  #38 = Utf8               java/lang/System
  #39 = Utf8               out
  #40 = Utf8               Ljava/io/PrintStream;
  #41 = Utf8               java/io/PrintStream
  #42 = Utf8               println
  #43 = Utf8               (Ljava/lang/String;)V
{
  public com.boot.jdk.SyncUsingWay();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=1, locals=1, args_size=1
         0: aload_0
         1: invokespecial #1                  // Method java/lang/Object."**<init>**":()V
         4: return
      LineNumberTable:
        line 3: 0
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0       5     0  this   Lcom/boot/jdk/SyncUsingWay;
  public synchronized void SyncMethod();
    descriptor: ()V
    flags: ACC_PUBLIC, **ACC_SYNCHRONIZED**
    Code:
      stack=2, locals=1, args_size=1
         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #3                  // String SyncMethod
         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return
      LineNumberTable:
        line 5: 0
        line 6: 8
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0       9     0  this   Lcom/boot/jdk/SyncUsingWay;
  public static synchronized void StaticSyncMethod();
    descriptor: ()V
    flags: ACC_PUBLIC, **ACC_STATIC, ACC_SYNCHRONIZED**
    Code:
      stack=2, locals=0, args_size=0
         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #5                  // String StaticSyncMethod
         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return
      LineNumberTable:
        line 9: 0
        line 10: 8
  public void method();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=3, args_size=1
         0: aload_0
         1: dup
         2: astore_1
         **3: monitorenter //** **进入同步代码块（进入临界范围内，锁的原子内部）**
         4: getstatic     #2                 // Field java/lang/System.out:Ljava/io/PrintStream;
         7: ldc           #6                  // String method
         9: invokevitual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        12: aload_1
        **13: monitorexit //** **正常退出同步代码块**
        14: goto          22
        17: astore_2
        18: aload_1
        **19: monitorexit //****防止任何异常情况下，退出同步代码块。JVM** **仍然可以释放锁**
        20: aload_2
        21: athrow
        22: return
      **Exception table: //****配合异常退出 monitorexit**
         from    to  target type
             4    14    17   any
            17    20    17   any
      LineNumberTable:
        line 13: 0
        line 14: 4
        line 15: 12
        line 16: 22
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0      23     0  this   Lcom/boot/jdk/SyncUsingWay;
      StackMapTable: number_of_entries = 2
        frame_type = 255 /* full_frame */
          offset_delta = 17
          locals = [ class com/boot/jdk/SyncUsingWay, class java/lang/Object ]
          stack = [ class java/lang/Throwable ]
        frame_type = 250 /* chop */
          offset_delta = 4
SourceFile: "SyncUsingWay.java"
```



#### synchronized 的特性
1. 有序性 （读读 读写、写读、写写 互斥）
2. 可见性，排他性 （可见性是指多个线程访问⼀个资源时，该资源的状态、值信息等对于其他线程都是可见的。 synchronized和volatile都具有可见性，其中synchronized对⼀个类或对象加锁时，⼀个线程如果要访问该类或对象必须先获得它的锁，⽽这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到共享内存当中，保证资源变量的可见性。）
3. 原子性 (本质上是线程互斥保证的原子性)
4. 可重入性 （代码示例 ThreadReIn.java）
![Markword](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220630174521.png)

#### synchronized 的锁升级 -- 偏向锁
偏向锁使用的前提：
1. 至少JDK1.6 版本且开启了偏向锁配置。
  偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。
2. 被加锁的对象，没有真正、或者隐式的调用父类 Object 里边的hashcode方法。
	如果一旦调用了object的hashcode方法，那么我们的对象头里边就有真正的hashcode值了，如果偏向锁来进行markword的替换，至少要提供一个保存hashcode的地方吧？可惜的是，偏向锁并没有地方进行markword的保存，只有轻量级锁才会有“displace mark word
代码示例： SyncLockFlag.java
```java
public class SyncLockFlag {
    // 当我们开启了偏向锁，并且没有延迟开启的时候，新创建的对象的mark word 默认就是偏向锁状态的markword。
    // 只不过这个时候，因为没有现成争抢，除了我们的锁标志为和是否为偏向锁标志位，其他的位数都是0
    static MyObject myobject = new MyObject();
    public static void main(String[] args) throws InterruptedException {
        System.out.println("=====================未偏向线程的偏向锁============================");
        System.out.println(ClassLayout.parseInstance(myobject).toPrintable());
        HashMap map = new HashMap();
        map.put(myobject,""); //隐式的调用了hashcode方法: 会升级的轻量级锁，
        synchronized (myobject) {
            System.out.println("=====================偏向锁============================");
            System.out.println(ClassLayout.parseInstance(myobject).toPrintable());
        }
    }
    static class MyObject{
    }
}
```

为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在
**对象头: 存储线程ID**
**栈帧的锁记录里: 线程有自己的stack frame, lock record 储存当前线程的id**
存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向
**当前线程的偏向锁: id 的匹配** 。
如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的**偏向锁指向当前线程: 其实是cas 竞争替换线程id**

#### synchronized 的锁升级 --偏向锁的撤销
<img src="https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220702181859.png"/>

面试时只需要回答： 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。
偏向锁的撤销，需要等待**全局安全点**（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着(isalive)，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。
```java
public class SyncSyncLockRelease {
    static Thread A;
    static Thread B;
    public static void main(String[] args) {
        final List<Object> list = new ArrayList<>();
        A = new Thread() {
            @SneakyThrows
            @Override
            public void run() {
                Object a = new Object();
                list.add(a);
                System.out.println("AAAA加锁前" + ClassLayout.parseInstance(a).toPrintable());
				// 00000101  00000000 00000000 00000000
                synchronized (a) {
                    System.out.println("AAAA加锁中" + ClassLayout.parseInstance(a).toPrintable());
                // 00000101 00101000 00101010 00011011
                }
                System.out.println("AAAA加锁后" + ClassLayout.parseInstance(a).toPrintable());
                //防止竞争 执行完后唤醒线程B/ 确保A线程 死亡 Terminated
                // 00000101 00101000 00101010 00011011
                LockSupport.unpark(B);//唤醒b
            }
        };
        B = new Thread() {
            @Override
            public void run() {
                LockSupport.park();//等待
                Object a = list.get(0);
                System.out.println("线程BBBB加锁前" + ClassLayout.parseInstance(a).toPrintable());
                // 00000101 00101000 00101010 00011011 A的线程id
                synchronized (a) {
                    System.out.println("线程BBBB加锁中" + ClassLayout.parseInstance(a).toPrintable());
                // 01111000 11110101 01111100 00011100  轻量级锁 b的线程id
                // 这不是竞争，但是还是升级为
                }
                System.out.println("线程BBBB加锁后" + ClassLayout.parseInstance(a).toPrintable());
                // 00000001 00000000 0000000 0000000 无锁状态 （这不是锁降级，而是轻量级锁释放了）
                System.out.println("新产生的对象" + ClassLayout.parseInstance(new Object()).toPrintable());
                // 00000101 00000000 00000000 0000000
            }
        };
        A.start();
        B.start();
    }
}
```
偏向锁实验：
	1.  A线程获取偏向锁，并且A线程死亡退出。B线程争抢偏向锁，会直接升级当前对象的锁为轻量级锁。**这只是针对我们争抢了一次。**
	2.  A线程获取偏向锁，并且A线程没有释放偏向锁（），还在syhnc的代码块里边。B线程此时过来争抢偏向锁，会直接升级为重量级锁。    
	3.  A线程获取偏向锁，并且A线程释放了锁，但是A线程并没有死亡还在活跃状态。B线程过来争抢，会直接升级为轻量级锁。    
	综上所述，当我们尝试第一次竞争偏向锁时，如果A线程已经死亡，升级为轻量级锁；如果A线程未死亡，并且未释放锁，直接升级为重量级锁；如果A线程未死亡，并且已经释放了锁，直接升级为轻量级锁。
	4.  A线程获取偏向锁，并且A线程没有释放偏向锁（），还在syhnc的代码块里边。B线程多次争抢锁，会在加锁过程中采用重量级锁；但是，一旦锁被释放，当前对象还是会以轻量级锁的初始状态执行。这块算是锁降级吗？不算。这个示例就是我们一些博客论坛里边的一些认为可以锁降级的示例。--- 锁升级是在线程运行过程中和争抢过程中的一种升级。**这句话里一定要注意 中 这个字儿**，很重要。我想请问，刚才我们演示的是在竞争中的锁降级吗？
	5. A线程获取偏向锁，并且A线程释放了锁，但是A线程并没有死亡还在活跃状态。B线程过来争抢。部分争抢会升级为轻量级锁；部分争抢会依旧保持偏向锁。

偏向锁状态变化与最终升级为轻量级锁：
1.  A 线程获取偏向锁成功，已经退出执行不再是活跃线程； B线程过来获取偏向锁，默认前20次直接升级为轻量级锁 （触发批量重偏向阈值之前， 默认为 20次争抢，不同机器环境参数配置不一样）；
2.  A 线程获取偏向锁成功，已经退出执行不再是活跃线程； B线程过来获取偏向锁，默认20次以后，直接偏向线程 B。达到40次阈值后，若再有其他线程C过来争抢，则触发批量撤销。该对象不再有任何偏向锁的情况。
批量重偏向： 
	当我们的一个对象，Object 类，在经过默认 20次的争抢的情况下，会将后边的所有争抢从新偏向争抢的线程。1. 当B线程争抢第 18 次的时候，触发了批量重偏向的阈值；在第十八次以及以后的争抢里，jvm会将线程偏向线程b，因为jvm认为，这个对象更加适合线程B。
批量撤销：
	如果基于批量重偏向的基础上，还在继续进行争抢达到40次，并且有第三条线程C加入了，这个时候会触发批量撤销。JVM会标记该对象不能使用偏向锁，以后新创建的对象，直接以轻量级锁开始。 这个时候，才是真正的完成了锁升级。
**真正的锁升级，是依赖于 class 的，而并不是依赖于 某一个 new出来的对象（偏向锁升级为轻量级锁）。
真正的锁升级，是依赖于 当前new出来的对象的（轻量级锁升级为重量级锁）**


#### Synchronized 锁升级 - 轻量级锁的加锁与解锁
1. 轻量级锁加锁
线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间（Lock Record记录），并将对象头中的Mark Word（前30位 （25位的hashcode，4位的分代年龄，1位是否为偏向锁））复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针（指向线程栈帧里边的Lock Record的指针）。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
2. 轻量级锁解锁
轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word（Lock Record记录）替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。

轻量级锁升级为重量级锁：这个时候，只要我们的线程发生了竞争，并且CAS替换失败，就会发起锁膨胀，升级为重量级锁（针对的是一个对象实例）。
```java
// 关闭偏向锁的情况下的代码
public class LightLock {
	public static void main(String[] args) throws InterruptedException {
		Object obj = new Object();
		System.out.println("====A 加锁前==="+ClassLayout.parseInstance(obj).toPrintable());
		Thread A = new Thread() {
			@SneakyThrows
			@Override
			public void run() {
				synchronized (obj) {
					System.out.println("===A 加锁中==="+ClassLayout.parseInstance(obj).toPrintable());
					Thread.sleep(2000);
				}
			}
		};
		A.start();
		Thread.sleep(500);
		System.out.println("====B加锁前==="+ClassLayout.parseInstance(obj).toPrintable());
		Thread B = new Thread() {
			@SneakyThrows
			@Override
			public void run() {
				synchronized (obj) {
					System.out.println("====B加锁中==="+ClassLayout.parseInstance(obj).toPrintable());
					Thread.sleep(1000);
				}
			}
		};
		B.start();
		Thread.sleep(5000);
		synchronized (obj) {
			System.out.println("====再次加锁中==="+ClassLayout.parseInstance(obj).toPrintable());
		}
		Object objnew = new Object();
		synchronized (objnew) {
			System.out.println("====新对象加锁中==="+ClassLayout.parseInstance(objnew).toPrintable());
		}
	}
}
```
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220702181944.png)
轻量级锁---重量级锁： 释放锁（前四步）并唤醒等待线程
	1.  线程1 初始化monitor 对象；
	2.  将状态设置为膨胀中（inflating）；
	3.  将monitor里边的header属性，set称为对象的markword；（将自己lock record里边的存放的mark word的hashcode，分代年龄，是否为偏向锁 set 到 objectmonitor对象的header属性里）
	4.  设置对象头为重量级锁状态（标记为改为00）；然后将前30位指向第1不他初始化的monitor 对象；（真正的锁升级是由线程1操控的）
	5.  唤醒线程2；
	6.  线程2 开始争抢重量级锁。（线程2就干了一件事儿，就是弄了一个临时的重量级锁指针吧？还不是最后的重量级锁指针。因为最后的重量级锁指针是线程1初始化的并且是线程1修改的。 而且，线程2被唤醒之后，还不一定能够抢到这个重量级锁。Sync是非公平锁。 线程2费力不讨好，但是线程2做了一件伟大的事情：他是锁升级的奠基者。）

#### markword 的转化过程
创建一个对象，此时对象里边没有hashcode，所以该对象可以使用我们的偏向锁，偏向锁不会考虑hashcode，
他会直接将自己的线程id放到我们的markword里边，不需要考虑后续的替换问题。 所以呢，一旦我们的对象主动调用了Object的hashcode方法，我们的偏向锁就自动不可用了。

如果我们的对象有了hashcode和分代年龄和是否为偏向锁（30位）。在轻量级锁的状态下，这30位会被复制到我们的轻量级锁线程持有者的栈帧里的lock record里边记录。与此同时，我们的对象的markword里边存放的是我们的指向轻量级锁线程持有者的栈帧的lock recod里。如果一直存在轻量级锁竞争，在未发生锁膨胀的前提下，一直会保持轻量级锁，A线程释放的时候，会将markword替换回对象的markword里边，B线程下次再从新走一遍displace mark word；

一旦发生了轻量级膨胀为重量级锁。前提，A线程持有锁；B线程争抢。
B线程将marikword里边A线程的指针替换成一个临时的（过度的）重量级锁指针，为了让A线程在cas往回替换markword的时候失败。
A线程替换回markword失败后，会发起：1.初始化monitor对象；2. 将状态设置为膨胀中；3 将替换失败的 markword放到objectmonitro的head属性里； 4。改变markword的锁标志为10；将markword里的 30 位设置为指向自己第一步初始化的那个monitor对象；5唤醒B线程； 6以后这个对象只能作为重量级锁；
Markword从未丢失

#### 死锁
死锁产生的四个必要条件：
	- 互斥：一个资源每次只能被一个进程使用 (资源独立)。
	- 请求与保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放 (不释放锁)。
	- 不剥夺：进程已获得的资源，在未使用之前，不能强行剥夺 (抢夺资源)。
	- 循环等待：若干进程之间形成一种头尾相接的循环等待的资源关闭 (死循环)。
如何避免死锁
	1. 破坏” 互斥” 条件：系统里取消互斥、若资源一般不被一个进程独占使用，那么死锁是肯定不会发生的，但一般 “互斥” 条件是无法破坏的，因此，在死锁预防里主要是破坏其他三个必要条件，而不去涉及破坏 “互斥” 条件。
	2. 破坏 “请求和保持” 条件：
		方法 1：所有的进程在开始运行之前，必须一次性的申请其在整个运行过程各种所需要的全部资源。
		优点：简单易实施且安全。
		缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。
		方法 2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到，已经使用完毕的资源，然后再去请求新的资源。这样的话资源的利用率会得到提高，也会减少进程的饥饿问题。
	3. 破坏 “不剥夺” 条件：当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂的释放或者说被抢占了。
	4. 破坏 “循环等待” 条件：可以通过定义资源类型的线性顺序来预防，可以将每个资源编号，当一个进程占有编号为 i 的资源时，那么它下一次申请资源只能申请编号大于 i 的资源。
现在我们介绍避免死锁的几个常见方法。
	- 避免一个线程同时获取多个锁。
	- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
	- 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。
	- 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

#### ObjectMonitor 属性
1. header ： 重量级锁保存markword的地方
2. own: 指向我们持有锁的线程；对象的markword里边也保存了指向monitor的指针；
3. _cxq 队列： 竞争队列。 A线程持有锁没有释放； B和C线程同时过来争抢锁，都被block了，此时会将B和C线程加入到 该队列。
4. EntryList队列：同步队列。A线程释放锁，B和C线程中会选定一个继承者（可以去争抢锁的这个线程），另外一个线程会被放入我们的EntryList队列里边。 
5. waitset：等待队列。Object wait的线程。
	A线程持有锁，BC线程过来竞争失败，进入cxq -- 下轮竞争会把 cxq里的线程移动到EntrylIst中。假设B线程竞争到了锁，然后B线程调用了 Object.Wait方法，这时候B线程进入waitset，并释放锁。C线程拿到了锁，然后唤醒B线程。B线程会从waitset里边出来，直接竞争锁。如果竞争失败进入cxq，继续轮回，如果竞争成功，ok了。


### Ch3 Java 内存模型
#### Java内存模型基础
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220703222549.png)

Java的并发采用的是共享内存模型，Java线程之间的通信总是**隐式进行**，整个通信过程对程序员完全透明。
在Java中，所有**实例域、静态域和数组元素**都存储在堆内存中，**堆内存在线程之间共享**（“共享变量”这个术语代指实例域，静态域和数组元素）。**局部变量**（Local Variables），**方法定义参数**（Java语言规范称之为Formal Method Parameters）和**异常处理器参数**（Exception Handler Parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。
Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。

#### 指令重排序
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220703222530.png)
在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。
	1. 编译器优化的重排序。编译器在不改变**单线程程序语义**的前提下，可以重新安排语句的执行顺序。
	2. 指令级**并行**的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令**重叠**执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
	3. **内存系统的重排序**。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。
对于处理器重排序，**JMM的处理器重排序规则会要求   <mark>Java编译器</mark> 在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令**，通过内存屏障指令来禁止特定类型的处理器重排序。
JMM属于**语言级**的内存模型，它确保在**不同的编译器和不同的处理器**平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。
#### 内存屏障
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220703222613.png)
StoreLoad Barriers是一个**全能型**的屏障，它同时具有其他3个屏障的效果。执行该屏障开销会很昂贵，因为**当前处理器通常要把写缓冲区中的数据全部刷新到内存中**（Buffer Fully Flush）。
#### Happens-Before 原则
happens-before是JMM最核心的概念。对应Java程序员来说，理解happens-before是理解JMM的关键。

从JDK 5开始，Java使用新的JSR-133内存模型。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。

与程序员密切相关的happens-before规则如下。
1）程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
2）监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
3）volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
4）传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。
6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。

两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前
#### as-if-serial 语义
as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。

为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。

**happens-before关系本质上和as-if-serial语义是一回事。**
as-if-serial语义保证**单线程内程序**的执行结果不被改变，happens-before关系保证**正确同步的多线程程序**的执行结果不被改变。
as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。
as-if-serial语义和happens-before这么做的目的，都是为了在**不改变程序执行结果**的前提下，尽可能地提高程序执行的**并行度**。
#### 锁的获取 与释放内存的语义
```java
class MonitorExample {
    int a = 0;
    public synchronized void writer() {　　　　 // 1
        a++;　　　　　　　　　　                // 2
    }　　　　　　　　　　　　                   // 3
    public synchronized void reader() {　　　   // 4
        int i = a;　　　　　　　　              // 5
        ……
    }　　　　　　　　　　　　                   // 6
}
```
线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对**共享变量所做修改的**）消息。
线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。
线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。（**隐式通信**）
### Ch4 Volatile 全解读
保证可见性
禁止指令重排序 如何使用的内存屏障？
双重检查锁： 如何解决问题
#### Volatile 定义
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220704000100.png)
在多线程并发编程中synchronized和volatile都扮演着重要的角色，**volatile是轻量级的synchronized**，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为**它不会引起线程上下文的切换和调度**。

Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁要更加方便（**读多写少**）（因为从cpu 缓存中读取，不用内存）。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。
#### Volatile 保障可见性原理
volatile是如何来保证可见性的呢？对volatile进行写操作时，CPU会做什么事情。
如 Java代码如下。
`instance = new Singleton();                 // instance是volatile变量`
转变成汇编代码，如下。
`0x01a3de1d: movb $0×0,0×1104800(%esi);`
`0x01a3de24: lock addl $0×0,(%esp);`

有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事情。

1. 将当前处理器缓存行的数据写回到系统内存（主存。<mark>声言Lock信号</mark>。）
	Lock前缀指令会引起处理器缓存回写到内存。Lock前缀指令导致在执行指令期间，**声言处理器的LOCK#信号**。在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以**独占**任何共享内存（主存只有当前处理器一个人可以访问，锁总线）。但是，在**最近的处理器里，LOCK＃信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大**。对于Intel486和Pentium处理器，在锁操作时，总是在总线上声言LOCK#信号。但在P6和目前的处理器中，如果访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。相反，它会锁定这块内存区域的缓存并回写到内存（**总线锁定声言lock信号的，为了提高性能，高级的处理器走的是缓存锁定，改哪里锁定哪里，所以不需要声言lock信号**。），并使用缓存一致性机制来确保修改的原子性，此操作被称为“**缓存锁定**”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。
2. 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。
	一个处理器的缓存回写到内存会导致其他处理器的缓存无效。IA-32处理器和Intel 64处理器使用**MESI（修改、独占、共享、无效**）控制协议去维护内部缓存和其他处理器缓存的一致性。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用**嗅探**技术保证它的内部缓存、系统内存和其他处理器的缓存的**数据在总线上保持一致**。例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。
	
为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来**检查自己缓存的值是不是过期了**，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行**设置成无效状态**，当处理器对这个数据进行修改操作的时候，会**重新从系统内存中把数据读到处理器缓存里**。
#### Volatile 优化案例
> JVM 缓存行 

Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类Linked-TransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性能。
它使用一个内部类类型来定义队列的头节点（head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对象的引用占4个字节，**它追加了15个变量（共占60个字节**），再加上父类的value变量，一共64个字节。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220705191255.png)
为什么追加64字节能够提高并发编程的效率呢？
	因为对于英特尔酷睿i7、酷睿、Atom和NetBurst，以及Core Solo和Pentium M处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行，这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使用追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，使头、尾节点在修改时不会互相锁定。

那么是不是在使用volatile变量时都应该追加到64字节呢？不是的。在两种场景下不应该使用这种方式。
	- **缓存行非64字节宽的处理器**。如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个字节宽。
	- **共享变量不会被频繁地写**。因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，这本身就会带来一定的性能消耗，如果共享变量不被频繁写的话，**锁的几率也非常小，就没必要通过追加字节的方式来避免相互锁定**

#### Volatile禁止指令重排序
为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。
下面是基于保守策略的JMM内存屏障插入策略
	在每个volatile写操作的**前面**插入一个**StoreStore**屏障。
	在每个volatile写操作的**后面**插入一个**StoreLoad**屏障。
	在每个volatile读操作的**后面**插入一个**LoadLoad**屏障。
	在每个volatile读操作的**后面**插入一个**LoadStore**屏障。
	![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220705234726.png)
StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。

这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在采取了保守策略：在**每个volatile写的后面，或者在每个volatile读的前面插入一个StoreLoad屏障**。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：**一个写线程写volatile变量，多个读线程读同一个volatile变量**。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。
问题1： 为什么读操作都是后面加入屏障
	其实 也是可以在volatile 读前面加入storeload的屏障。 但是为了多读少写的情况优化
问题2： 普通写应该跟volatile 没有关系，为什么还要StoreStore屏障

![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220706113123.png)
**上述volatile写和volatile读的内存屏障插入策略非常保守**。在实际执行时，只要不改变volatile写-读的内存语义，**编译器可以根据具体情况省略不必要的屏障**。下面通过具体的示例代码进行说明。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220706113240.png)
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220706113248.png)
#### Volatile 内存语义增强
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220706150216.png)
- 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。
- 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。
- 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。
在JSR-133之前的旧Java内存模型中，**虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量重排序**。这样<mark>会产生问题</mark>。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220706201109.png)
在旧的内存模型中，当1和2之间没有数据依赖关系时，1和2之间就可能被重排序（3和4类似）。其结果就是：读线程B执行4时，不一定能看到写线程A在执行1时对共享变量的修改。


#### 双重检查错问题的根源
new 是JVM 的操作它分为3个步骤，这三个步骤如果重排序可能会导致检查锁的失效。
```java
1. memory = allocate() // 分配对象内存空间
2. ctorInstance(memory) // 初始化对象
3. instance = memory // 设置instance 指向刚分配的内存地址

1. memory = allocate() // 分配对象内存空间
3. instance = memory // 设置instance 指向刚分配的内存地址
2. ctorInstance(memory) // 初始化对象
// 此时instance 就不为null
```
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220706201143.png)

#### 双重检查锁两种解决方式
1. 基于 Volatile 的解决方案
	大众式的讲解。因为面试过程中，绝大多数面试官都认为是volatile禁止了 new 对象里边三行代码的重排序。
	因为new instance 他是一个 JVM 指令码，对应的是 new 指令。 Volatile能够保障单个JVM 指令的原子性，所以此处， new instace相当于是volatiole写，会在 new instance前加 storestore，后加storeload屏障，b线程就必须在storeload 屏障后边读取。（**不建议面试使用**）实质上，new对象里边的三个小步骤，依然可以重排序，真正的控制是在外层的内存屏障控制。
2. JVM在类的初始化阶段（即在Class被加载后，且被线程使用之前），会执行类的初始化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。
	![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220707144219.png)![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220707144246.png)

### Ch5 Lock 全解读
#### 自定义lock 锁
SelfLock.java  SelfLockTest.java
```java
import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.AbstractQueuedSynchronizer;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;

public class SelfLock implements Lock {
    // AQS 呢？如何使用呢？
    private static class Sync extends AbstractQueuedSynchronizer {
        //加锁的时候用 state int 类型
        public boolean tryAcquire(int acquires) {
                if(compareAndSetState(0, acquires)) {
                    setExclusiveOwnerThread(Thread.currentThread());
                    return true;
                }
                return false;
        }
        //解锁的
        public boolean tryRelease(int releases) {
            if(getState() == 0) {
                throw new IllegalMonitorStateException();
            }
            setState(0); // 不用，当前线程释放锁，说明，当前线程持有锁。
            return true;
        }
        //创建condition. wait notify
        Condition newCondition(){
            return new ConditionObject();
        }

        public boolean isLocked(){
            //锁定的话，state == 1
            return getState() == 1;
        }
    }

    private final Sync sync = new Sync();

    public void lock() {
//        sync.tryAcquire(); //调用错误
        sync.acquire(1); //传说中的模板方法吗？ 是的
    }
    public boolean tryLock() {
        return sync.tryAcquire(1);
    }
    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {
        return sync.tryAcquireNanos(1, unit.toNanos(time));
    }
    public void lockInterruptibly() throws InterruptedException {
        sync.acquireInterruptibly(1);
    }
    public void unlock() {
        sync.release(1);
    }
    public Condition newCondition() {
        return sync.newCondition();
    }
    public boolean isLocked(){
        return sync.isLocked();
    }
    public boolean hasQueuedThreads(){
        return sync.hasQueuedThreads();
    }
}
```

```java
import java.util.concurrent.locks.Lock;

public class SelfLockTest {
    static Lock lock = new SelfLock();
    public static void main(String[] args) throws InterruptedException {
        Thread A = new Thread(() -> {
            testLock();
        });
        Thread B = new Thread(() -> {
            testLock();
        });
        A.setName("I am A");
        B.setName("I am B");
        A.start();
        Thread.sleep(100);
        B.start();
    }
    public static void testLock() {
        System.out.println("I want IN。。。。");
        lock.lock();
        try {
            System.out.println("我获取到锁了，哈哈！线程名称 = "
                    + Thread.currentThread().getName());
            while (true) {

            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }
}
```

#### 锁由来及特性和常用API
锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以**允许多个线程并发的访问共享资源，比如读写锁**）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。**虽然它缺少了**（通过synchronized块或者方法所提供的）**隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性**。

使用synchronized关键字将会隐式地获取锁，但是它将锁的获取和释放固化了，也就是先获取再释放。当然，这种方式简化了同步的管理，可是扩展性没有显示的锁获取和释放来的好。

在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。
**不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。**
![Lock 锁的特性](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220709114153.png)
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220709114251.png)

#### 队列同步器-AQS 底层原理
队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，它使用了一个**int成员变量表示同步状态**，通过内置的**FIFO队列**来完成资源获取线程的排队工作，并发包的作者（Doug Lea）期望它能够成为实现大部分同步需求的基础。

同步器的主要使用方式是**继承**，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。

子类推荐被定义为自定义同步组件的**静态内部类**，同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。

同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。

同步器的设计是基于模板方法模式的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220709114516.png)
重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。
- getState()：获取当前同步状态。
- setState(int newState)：设置当前同步状态。
- compareAndSetState(int expect,int update)：使用**CAS**设置当前状态，该方法能够保证状态设置的原子性。

同步器依赖内部的**同步队列（一个FIFO双向队列**）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。

节点是构成同步队列（等待队列，在Condition中将会介绍）的基础，同步器拥有首节点（head）和尾节点（tail），没有成功获取同步状态的线程将会成为节点加入该队列的尾部，同步队列的基本结构如图所示。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220709152438.png)
同步队列Aqs 为什么在设置尾结点的时候需要使用CAS:
	三个线程abc，a持有锁，bc竞争失败，需要添加到 AQS的同步队列的尾端。此时bc同时竞争tail节点，这个时候就是要保证线程安全性，正确的添加尾节点，需要使用cas操作。

同步队列设置 头节点，需要使用cas吗？
	不需要，因为设置头节点的线程是已经获取锁成功的线程，这个时候只有一条线程获取锁成功了，所以直接普通**setHead**节点就可以了。没有竞争，就无需保证安全性。

#### ReentrantLock code
不同的版本 差异还是挺大的 Java8
```java
// test.java
public class ReentrantLockTest {
	static ReentrantLock lock = new ReentrantLock();
	static ReentrantLock lock1 = new ReentrantLock(true);
	public static void main(String[] args) throws InterruptedException {
	/*
	* AQS-compareAndSetState
	* acquire
	* addWaiter
	* enq
	* acquireQueued
	* shouldParkAfterFailedAcquire
	* parkAndCheckInterrupt
	* cancelAcquire
	* */
	// acquire 方法是 aqs提供的模板方法，是为了进行锁的获取；tryAcquire 方法是aqs提供的可以复写的方法，主要是完成了加锁状态变化的逻辑（state）；
	// addWaiter 将我们的获取失败的线程放到我们的同步队列里；enq 如果addwaiter第一次没有成功，就进行死循环添加；acquireQueued：这部分其实是通过循环的自我检查，如果当前节点的pred节点是头节点，那么就尝试获取锁；
	//如果不是头节点，就调用 shouldParkAfterFailedAcquire 方法，判断pred节点是否为 SIGNAL 状态，如果是signal状态，自己就好好的等着；如果是 cancell状态，就移除cancell的节点。其他状态的节点，会通过cas操作替换为 SIGNAL状态。

	lock.lock();
	//	ReetrantLock:: sync.lock(); >>> nofair.
	//  AQS:: compareAndSetState
	//  AQS:: accquire
	//  AQS:: tryAcquire, addWaiter
/**
*AQS - tryAcquireNanos
* doAcquireNanos
* shouldParkAfterFailedAcquire
*
*/
//tryLock（） 为了进行一次性的获取锁，如果获取成功则成功，如果失败则失败
//tryLock(1,null) 在超时时间以内，循环获取锁、
lock.tryLock();
lock.tryLock(1,null); //InterruptedException
/**
* AQS -acquireInterruptibly
*/
// lockInterruptibly方法，是一个支持中断的加锁方式。他与 lock.tryLock(1,null) 这个有什么区别？
// 相同点：都支持中断
//不同点： lockInterruptibly方法仅仅支持中断；不支持超时。lock.tryLock(1,null)即支持超时，也支持超时内的时间中断
lock.lockInterruptibly();
lock.isHeldByCurrentThread();
  
/**
* AQS - release
* unparkSuccessor
*
*/
// 调用tryRelease，直到释放掉所有的锁（state =0），因为考虑有重入的情况。然后唤醒后继（unparkSuccessor）线程让他进行锁竞争。

lock.unlock();
/**
* AQS - hasQueuedPredecessors // 如果新线程来了，它在queue里吗？没在q里就没有pre节点。没办法，直接加入tail
* 他是公平锁的关键方法
*/
lock1.lock();

```
```java
// ReentrantLock part code
private final Sync sync;
// 这个只是父类，还有两个子类fairlock non-fair Lock 实现了
abstract static class Sync extends AbstractQueuedSynchronizer {
	private static final long serialVersionUID = -5179523762034025860L;
	/**
	* Performs {@link Lock#lock}. The main reason for subclassing
	* is to allow fast path for nonfair version.
	*/
	abstract void lock();
	/**
	* Performs non-fair tryLock. tryAcquire is implemented in
	* subclasses, but both need nonfair try for trylock method.
	*/
	final boolean nonfairTryAcquire(int acquires) {
		final Thread current = Thread.currentThread();
		int c = getState();
		if (c == 0) {
			if (compareAndSetState(0, acquires)) {
				setExclusiveOwnerThread(current);
				return true;
			}
		}else if (current == getExclusiveOwnerThread()) {
			int nextc = c + acquires;
			if (nextc < 0) // overflow
			throw new Error("Maximum lock count exceeded");
			setState(nextc);
			return true;
		}
		return false;
	}
	protected final boolean tryRelease(int releases) {
		int c = getState() - releases;
		if (Thread.currentThread() != getExclusiveOwnerThread())
			throw new IllegalMonitorStateException();
		boolean free = false;
		if (c == 0) {
			free = true;
			setExclusiveOwnerThread(null);
		}
		setState(c);
		return free;
	}
}
/**
* Sync object for non-fair locks
*/
static final class NonfairSync extends Sync {
	private static final long serialVersionUID = 7316153563782823691L;
	/**
	* Performs lock. Try immediate barge, backing up to normal
	* acquire on failure.
	*/
	final void lock() {
		if (compareAndSetState(0, 1))
			setExclusiveOwnerThread(Thread.currentThread());
		else
			acquire(1);
		}
	protected final boolean tryAcquire(int acquires) {
			return nonfairTryAcquire(acquires);
	}
}


static final class FairSync extends Sync {
	private static final long serialVersionUID = -3000897897090466540L;
	final void lock() {
		acquire(1);
	}
	/**
	* Fair version of tryAcquire. Don't grant access unless
	* recursive call or no waiters or is first.
	*/
	protected final boolean tryAcquire(int acquires) {
		final Thread current = Thread.currentThread();
		int c = getState();
		if (c == 0) {
			if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) {
				setExclusiveOwnerThread(current);
				return true;
			}
		}
		else if (current == getExclusiveOwnerThread()) {
			int nextc = c + acquires;
			if (nextc < 0)
				throw new Error("Maximum lock count exceeded");
			setState(nextc);
			return true;
		}
		return false;
	}
}
final boolean nonfairTryAcquire(int acquires) {
	final Thread current = Thread.currentThread();
	int c = getState();
	if (c == 0) {
		if (compareAndSetState(0, acquires)) {
			setExclusiveOwnerThread(current);
		return true;
		}
	}
	else if (current == getExclusiveOwnerThread()) {// 自己 冲入
		int nextc = c + acquires;
		if (nextc < 0) // overflow
			throw new Error("Maximum lock count exceeded");
		setState(nextc);
		return true;
	}
	return false;
}

protected final boolean tryRelease(int releases) {
	int c = getState() - releases;
	if (Thread.currentThread() != getExclusiveOwnerThread())
		throw new IllegalMonitorStateException();
	boolean free = false;
	if (c == 0) {
		free = true;
		setExclusiveOwnerThread(null);
	}
	setState(c);
	return free;
}
```
```java
//AQS
public final void acquire(int arg) {
	if (!tryAcquire(arg) &&
	acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
		selfInterrupt();
}
/**
* Acquires in exclusive uninterruptible mode for thread already in
* queue. Used by condition wait methods as well as acquire.
* @param node the node
* @param arg the acquire argument
* @return {@code true} if interrupted while waiting
*/
final boolean acquireQueued(final Node node, int arg) {
	boolean failed = true;
	try {
		boolean interrupted = false;
		for (;;) {// 循环队列 看自己有没有拿到锁
			final Node p = node.predecessor();
			if (p == head && tryAcquire(arg)) {// 拿到锁
				setHead(node);
				p.next = null; // help GC
				failed = false;
				return interrupted;
			}
			if (shouldParkAfterFailedAcquire(p, node) &&
				parkAndCheckInterrupt()) //没有拿到锁： 检查是否因该挂起
				interrupted = true;
		}
	} finally {
		if (failed)
			cancelAcquire(node);
	}
}
/**
* Creates and enqueues node for current thread and given mode.
* @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared
* @return the new node
*/
private Node addWaiter(Node mode) {
	Node node = new Node(Thread.currentThread(), mode);
	// Try the fast path of enq; backup to full enq on failure
	Node pred = tail;
	if (pred != null) {// tail 不为空
		node.prev = pred;
		if (compareAndSetTail(pred, node)) {// CAS b c 线程竞争
			pred.next = node;
			return node;
		}
	}
	enq(node); // tail 为空
	return node;
}

private Node enq(final Node node) {
	for (;;) {// 死循环， 一定要添加上
		Node t = tail;
			if (t == null) { // Must initialize
				if (compareAndSetHead(new Node()))
					tail = head;// 初始化设置头尾
			} else { // t 如果这时候不为空（被别的线程初始化）
				node.prev = t;
				if (compareAndSetTail(t, node)) {
					t.next = node;
					return t;
			}
		}
	}
}

private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
	int ws = pred.waitStatus;
	if (ws == Node.SIGNAL)
		/*
		* This node has already set status asking a release
		* to signal it, so it can safely park.
		*/
		return true;
	if (ws > 0) {
		/*
		* Predecessor was cancelled. Skip over predecessors and
		* indicate retry.
		*/
		do {
			node.prev = pred = pred.prev;
		} while (pred.waitStatus > 0);
			pred.next = node;
		} else {
			/*
			* waitStatus must be 0 or PROPAGATE. Indicate that we
			* need a signal, but don't park yet. Caller will need to
			* retry to make sure it cannot acquire before parking.
			*/
			compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
		}
	return false;
}

static void selfInterrupt() {
	Thread.currentThread().interrupt();// 设置中断标志，没有必要一直自旋
}


/**
* Convenience method to park and then check if interrupted
* @return {@code true} if interrupted
*/
private final boolean parkAndCheckInterrupt() {
	LockSupport.park(this);
	return Thread.interrupted();
}

private void cancelAcquire(Node node) {
// Ignore if node doesn't exist
	if (node == null)
		return;  
	node.thread = null;
	// Skip cancelled predecessors
	Node pred = node.prev;
	while (pred.waitStatus > 0)
		node.prev = pred = pred.prev;
	// predNext is the apparent node to unsplice. CASes below will
	// fail if not, in which case, we lost race vs another cancel
	// or signal, so no further action is necessary.
	Node predNext = pred.next;
	// Can use unconditional write instead of CAS here.
	// After this atomic step, other Nodes can skip past us.
	// Before, we are free of interference from other threads.
	node.waitStatus = Node.CANCELLED;
	// If we are the tail, remove ourselves.
	if (node == tail && compareAndSetTail(node, pred)) {
		compareAndSetNext(pred, predNext, null);
	} else {
	// If successor needs signal, try to set pred's next-link
	// so it will get one. Otherwise wake it up to propagate.
		int ws;
		if (pred != head &&
		((ws = pred.waitStatus) == Node.SIGNAL ||
		(ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&
		pred.thread != null) {
			Node next = node.next;
			if (next != null && next.waitStatus <= 0)
				compareAndSetNext(pred, predNext, next);
			} else {
				unparkSuccessor(node);
			}
		  
		node.next = node; // help GC
	}
}
public final boolean tryAcquireNanos(int arg, long nanosTimeout)
		throws InterruptedException {
	if (Thread.interrupted()) // 检查是否被中断
		throw new InterruptedException();
	return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);
}


private boolean doAcquireNanos(int arg, long nanosTimeout)
		throws InterruptedException {
	if (nanosTimeout <= 0L)
		return false; // 小于0 报错
	final long deadline = System.nanoTime() + nanosTimeout;
	final Node node = addWaiter(Node.EXCLUSIVE);
	boolean failed = true;
	try {
		for (;;) {
			final Node p = node.predecessor();
			if (p == head && tryAcquire(arg)) {
				setHead(node);
				p.next = null; // help GC
				failed = false;
				return true;
			}
			nanosTimeout = deadline - System.nanoTime();
			if (nanosTimeout <= 0L)
				return false;
			if (shouldParkAfterFailedAcquire(p, node) &&
					nanosTimeout > spinForTimeoutThreshold)
				LockSupport.parkNanos(this, nanosTimeout);
			if (Thread.interrupted())
				throw new InterruptedException();
		}
	} finally {
		if (failed)
			cancelAcquire(node);
	}
}
/**
* Releases in exclusive mode. Implemented by unblocking one or
* more threads if {@link #tryRelease} returns true.
* This method can be used to implement method {@link Lock#unlock}.
*
* @param arg the release argument. This value is conveyed to
* {@link #tryRelease} but is otherwise uninterpreted and
* can represent anything you like.
* @return the value returned from {@link #tryRelease}
*/
public final boolean release(int arg) {
	if (tryRelease(arg)) { // 还是继承的
		Node h = head;
		if (h != null && h.waitStatus != 0)
			unparkSuccessor(h);
		return true;
	}
		return false;
}
```
#### Node 状态 获取锁的流程图
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220710155711.png)
SIGNAL：等待被通知状态，如果pre节点是这个状态，那么当前节点就会进行park操作
_Cancelled_ ： 一个取消的线程状态。这个状态的线程会被移除。
```java

```

#### 公平锁
1. synchronized 他是一个非公平锁。
2. Lock分为非公平锁（默认） 还有公平锁。非公平锁： 当我们的线程在同步队列里排队完成之后，**获取锁的时候，这个时间点上如果有其他新的线程来竞争锁，那么我当前的排队的锁可能**<mark>会被插队</mark>（当前线程可能竞争不过新来的线程，导致自己竞争锁失败。）  这是不公平的，我（当前线程） 已经在同步队列里排了好长时间了，你这新来的线程直接抢走了。 公平锁：获取锁的时候，这个时间点上如果有其他新的线程来竞争锁，**那么新的线程会直接加入到同步队列里**（源码），cas set tail。
4. 性能比较（公平和非公平）：**肯定是非公平锁性能更高**。（都要+同步队列里，都要进行我们源码中的一系列的操作；**公平锁会有更多的上下文切换， 挂起，park（）**）
5. 非公平锁容易造成线程**饥饿**。（会被插队，极限情况考虑，如果一直被插队，同步队列里的其他线程就等着呗，饥饿。）
6. 很多情况我们在进行实战开发的时候，如果要**限定我们的线程的访问先后顺序，就要使用公平锁了**
#### ReetrantReadWriteLock 原理
在没有读写锁支持的（Java 5之前）时候，如果需要完成上述工作就要使用Java的等待通知机制，就是当写操作开始时，所有晚于写操作的读操作均会进入等待状态，只有写操作完成并进行通知之后，所有等待的读操作才能继续执行（写操作之间依靠synchronized关键进行同步），这样做的目的是使读操作能读取到正确的数据，不会出现脏读。改用读写锁实现上述功能，只需要在读操作时获取读锁，写操作时获取写锁即可。当写锁被获取到时，后续（非当前写操作线程）的读写操作都会被阻塞，写锁释放之后，所有操作继续执行，编程方式相对于使用等待通知机制的实现方式而言，变得简单明了。

一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，**读写锁能够提供比排它锁更好的并发性和吞吐量**。Java并发包提供读写锁的实现是ReentrantReadWriteLock，它提供的特性如表
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220710224032.png)
读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，**而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键**。
如果在一个整型变量上维护多种状态，就一定需要“**按位切割使用**”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，划分方式如图：
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220710230048.png)
当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。读写锁是如何迅速确定读和写各自的状态呢？答案是**通过位运算**。假设当前同步状态值为S，写状态等于S&0x0000FFFF（将高16位全部抹去），读状态等于S>>>16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1<<16)，也就是S+0x00010000。
根据状态的划分能得出一个推论：S不等于0时，当写状态（S&0x0000FFFF）等于0时，则读状态（S>>>16）大于0，即读锁已被获取。

写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（高16位读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态，获取写锁的代码源码所示。

该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断（如果我想写，必须确保没有读线程，也没有写线程）。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。

写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。
```java
// 有两吧锁
lock.writelock().lock()
lock.readlock().lock()
protected final boolean tryAcquire(int acquires) {
	/*
	* Walkthrough:
	* 1. If read count nonzero or write count nonzero
	* and owner is a different thread, fail.
	* 2. If count would saturate, fail. (This can only
	* happen if count is already nonzero.)
	* 3. Otherwise, this thread is eligible for lock if
	* it is either a reentrant acquire or
	* queue policy allows it. If so, update state
	* and set owner.
	*/
	Thread current = Thread.currentThread();
	int c = getState();
	int w = exclusiveCount(c);
	if (c != 0) {
		// (Note: if c != 0 and w == 0 then shared count != 0)
		if (w == 0 || current != getExclusiveOwnerThread())
			return false;
		if (w + exclusiveCount(acquires) > MAX_COUNT)
			throw new Error("Maximum lock count exceeded");
		// Reentrant acquire
		setState(c + acquires);
		return true;
	}
	if (writerShouldBlock() ||
		!compareAndSetState(c, c + acquires))
		return false;
	setExclusiveOwnerThread(current);
	return true;
}
```


#### ReentrantReadWriteLock 锁降级
锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。
锁降级中读锁的获取是否必要呢？答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。

#### LockSupport 工具类
当需要阻塞或唤醒一个线程的时候，都会使用LockSupport工具类来完成相应工作。LockSupport定义了一组的公共静态方法，这些方法提供了最基本的线程阻塞和唤醒功能，而LockSupport也成为构建同步组件的基础工具。
LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程。Park有停车的意思，假设线程为车辆，那么park方法代表着停车，而unpark方法则是指车辆启动离开，这些方法以及描述如表：
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220710232846.png)
在Java 6中，LockSupport增加了park(Object blocker)、parkNanos(Object blocker,long nanos)和parkUntil(Object blocker,long deadline)3个方法，用于实现阻塞当前线程的功能，其中参数blocker是用来标识当前线程在等待的对象（以下称为阻塞对象），该对象主要用于问题排查和系统监控。
下面的示例中，将对比parkNanos(long nanos)方法和parkNanos(Object blocker,long nanos)方法来展示阻塞对象blocker的用处，代码片段和线程dump（部分）如下图所示。
从下图线程dump结果可以看出，代码片段的内容都是阻塞当前线程10秒，但从线程dump结果可以看出，有阻塞对象的parkNanos方法能够传递给开发人员更多的现场信息
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220710232910.png)

#### Condition 解读
任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式，但是这两者在使用方式以及功能特性上还是有差别的。
通过对比Object的监视器方法和Condition接口，可以更详细地了解Condition的特性，对比项与结果下所示。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220710232946.png)

#### Condition 的原理
生产消费模型
```java
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
  
public class LockCondition<T> {
    private Object[]    items;
    // 添加的下标，删除的下标和数组当前数量
    private int addIndex, removeIndex, count;
    private Lock lock     = new ReentrantLock(); //创建锁
    private Condition notEmpty = lock.newCondition();//创建condition。 1个等待队列
    private Condition notFull = lock.newCondition();//创建condition   2个等待队列
    // 是不是我们的阻塞队列都是如此实现的呢？ 后续我们会对队列进行一个分析，也会看源码，到时候你就能看到
    //队列的头和队列的尾都是分别创建了一个condition，就是为了将我们的队列的双端的等待队列进行区分，互不影响。
    public LockCondition(int size) {
        items = new Object[size];
    }
    // 添加一个元素，如果数组满，则添加线程进入等待状态，直到有"空位"
    public void add(T t) throws InterruptedException {
        lock.lock();
        try {
            while (count == items.length) // 如果生产已满
                notFull.await(); //生产者暂定生产，去等待队列吧
            items[addIndex] = t;
            if (++addIndex == items.length)
                addIndex = 0;
            ++count;
            notEmpty.signal(); //告诉消费者线程开始消费吧
        } finally {
            lock.unlock();
        }
    }
    // 由头部删除一个元素，如果数组空，则删除线程进入等待状态，直到有新添加元素
    @SuppressWarnings("unchecked")
    public T remove() throws InterruptedException {
        lock.lock();
        try {
            while (count == 0)
                notEmpty.await(); //没东西了，消费者的线程无法进行消费，进入等待队列
            Object x = items[removeIndex];
            if (++removeIndex == items.length)
                removeIndex = 0;
            --count;
            notFull.signal();// 通知生产者线程赶紧工作。
            return (T) x;
        } finally {
            lock.unlock();
        }
    }
}
```
ConditionObject是同步器AbstractQueuedSynchronizer的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类也较为合理。**每个Condition对象都包含着一个队列**（以下称为**等待队列**），该队列是Condition对象实现等待/通知功能的关键。

等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类AbstractQueuedSynchronizer.Node。（NodeStatus CONDITION = -2; SIGNAL=-1;CANCELLED=1）
一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列。

Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点**引用更新的过程并没有使用CAS保证**(因为我们调用await方法的线程当前是持有锁的)，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。

![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712112031.png)
一个线程持有锁，调用了await方法之后加入了等待队列进行排队，当我们的这个线程被唤醒（需要执行await后边的代码），需要从新竞争我们的锁（因为await方法将锁释放掉了）。如果竞争成功还行，如果竞争失败，就会加入到同步队列里进行排队。如果排到了同步队列的头部且争抢锁成功，就继续执行await方法后边的代码。如果在执行过程中又调用了await方法，就再次回到等待队列。依次循环下去**多个对列，一起排队**。

#### Condition 源码 await siginal
```java
//我们主要看的是await方法的一个锁释放的逻辑。
public final void await()throws InterruptedException{
	if (Thread.interrupted())
		throw new InterruptedException
	Node node = addConditionWatier();
	int savedState =  fullyRelease(node);
	int interruptMode = 0;
	....
	}
// signal方法代码比较简单。唤醒等待队列的第一个节点
Node first = firstWaiter;
if (first != null)
	doSignal(first);
```
### Ch6 原子操作类
#### 什么是原子操作类
**原子操作类：提供了可以保证我们线程安全的类。可以直接使用。**

当程序更新一个变量时，如果多线程同时更新这个变量，可能得到期望之外的值，比如变量i=1，A线程更新i+1，B线程也更新i+1，经过两个线程操作之后可能i不等于3，而是等于2（1. 加锁，2定义我们的i变量为volatile形式。**3. 可以使用我们的一个原子操作类。**）。因为A和B线程在更新变量i的时候拿到的i都是1，这就是线程不安全的更新操作，通常我们会使用synchronized来解决这个问题，synchronized会保证多线程不会同时更新变量i。

而Java从JDK 1.5开始提供了java.util.concurrent.atomic包（以下简称Atomic包），这个包中的原子操作类提供了一种**用法简单、性能高效（CAS）、线程安全地更新一个变量的方式**。

因为变量的类型有很多种，所以在Atomic包里一共提供了13个类，属于4种类型的原子更新方式，分别是原子更新基本类型、原子更新数组、原子更新引用和原子更新属性（字段）。**Atomic包里的类基本都是使用Unsafe实现的包装类**。

#### 原子更新基本类型类
- AtomicBoolean：原子更新布尔类型。
- AtomicInteger：原子更新整型。
- AtomicLong：原子更新长整型。
- AtomicIntegerArray：原子更新整型数组里的元素。
- AtomicLongArray：原子更新长整型数组里的元素。
- AtomicReferenceArray：原子更新引用类型数组里的元素。
- AtomicReference：原子更新引用类型。
- AtomicReferenceFieldUpdater：原子更新引用类型里的字段。
- AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。
- AtomicLongFieldUpdater：原子更新长整型字段的更新器。
- AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题。

第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。
以上3个类提供的方法几乎一样，所以本节仅以AstomicIntegerFieldUpdater为例进行讲解

#### CountDownLatch
CountDownLatch 中 count down 是倒数的意思，latch 则是门闩的含义。整体含义可以理解为倒数完成后，门栓打开。倒数没有完成，门栓紧闭。CountDownLatch 类似于 join方法，等待其他线程执行完成后，才会统一继续执行下边的代码。在JDK 1.5之后的并发包中提供的CountDownLatch也可以实现join的功能，并且比join的功能更多。
常用方法说明：
- CountDownLatch(int count); //构造方法，创建一个值为count 的计数器。
- await();  //阻塞当前线程，将当前线程加入阻塞队列。
- await(long timeout, TimeUnit unit);//在timeout的时间之内阻塞当前线程,时间一过则当前线程可以执行
- countDown(); //对计数器进行递减1操作，当计数器递减至0时，当前线程会去唤醒阻塞队列里的所有线程。
#### CyclicBarrier
CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。

CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。
CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如，如果计算发生错误，可以重置计数器，并让线程重新执行一次。
CyclicBarrier还提供其他有用的方法，比如getNumberWaiting方法可以获得Cyclic-Barrier阻塞的线程数量。isBroken()方法用来了解阻塞的线程是否被中断。
示例代码： CyclicBarriesTest.java
需求：
1. 两条线程分别计算 （3*5） 和 （10+2）的结果
2. 结果计算完成后，将两个结果相加。（27）
4. 分别使用 CountDownLatch和CyclicBarrier两种方式进行代码开发，对比两者的区别。
#### Semaphore
Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。
Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制。
示例代码：SemaphoreTest.java
#### Exchanger
Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。

下面来看一下Exchanger的应用场景。Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。Exchanger也可以用于校对工作，比如我们需要将纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录入，录入到Excel之后，系统需要加载这两个Excel，并对两个Excel数据进行校对，看看是否录入一致。

示例代码：ExchangerTest.java




#### 线程安全的队列
在并发编程中，有时候需要使用线程安全的队列。如果要实现一个线程安全的队列有两种方式：一种是使用阻塞算法，另一种是使用非阻塞算法。使用阻塞算法的队列可以用一个锁（入队和出队用同一把锁）或两个锁（入队和出队用不同的锁）等方式来实现。非阻塞的实现方式则可以使用循环CAS的方式来实现

ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部；当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait-free”算法（即CAS算法）来实现。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712205819.png)
#### ConcurrentLinkedQueue 入队列
·添加元素1。队列更新head节点的next节点为元素1节点。又因为tail节点默认情况下等于head节点，所以它们的next节点都指向元素1节点。
·添加元素2。队列首先设置元素1节点的next节点为元素2节点，然后更新tail节点指向元素2节点。
·添加元素3，设置tail节点的next节点为元素3节点。
·添加元素4，设置元素3的next节点为元素4节点，然后将tail节点指向元素4节点。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712205948.png)


#### ConcurrentLinkedQueue 出队列
出队列的就是从队列里返回一个节点元素，并清空该节点对元素的引用。让我们通过每个节点出队的快照来观察一下head节点的变化，如图所示。
从图中可知，并不是每次出队时都更新head节点，当head节点里有元素时，直接弹出head节点里的元素，而不会更新head节点。只有当head节点里没有元素时，出队操作才会更新head节点。


![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712210054.png)



#### ArrayBlockingQueue 与 LinkedBlockingQueue
ArrayBlockingQueue是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。
LinkedBlockingQueue是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行。
相同点：
1. 都是阻塞队列，且有界；
2. 都是先进先出。
有什么区别呢？如果在实际工作中合理的选择呢？效率谁更好一些呢？

#### PriorityBlockingQueue 和 DelayQueue
PriorityBlockingQueue：
PriorityBlockingQueue是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现compareTo()方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。

DelayQueue：
DelayQueue是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。
DelayQueue非常有用，可以将DelayQueue运用在以下应用场景。
·缓存系统的设计(很少有公司自己设计大型缓存：Redis，ehcache，mcache)：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。
·定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，比如TimerQueue就是使用DelayQueue实现的。

#### SynchronousQueue
SynchronousQueue是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。

它支持公平访问队列。默认情况下线程采用非公平性策略访问队列。使用以下构造方法可以创建公平性访问的SynchronousQueue，如果设置为true，则等待的线程会采用先进先出的顺序访问队列。

1. 不存储数据的队列，阻塞队列。使用场景，适合短期的小并发场景，且数据处理相当快速。

硬要说点好处：首先他们有缓冲容量，那么他可以避免在服务器宕机的情况下，从queue的角度来说，没有数据丢失这么一说。 他类似于一个传球手，中间没有任何介质阻碍。如果单纯的进行数据的传递且生产的线程与消费的线程生产时间和消费时间都比较匹配的话，他的性能能够很高。

2.cachedThreadPool 里边使用的就是syncQueue。cachedThreadPool 的使用场景就是处理快速的短期的小并发场景。cachedThreadPool 是没有核心线程数，完全依赖max线程数，直接依赖操作系统创建线程，如果是短期的小并发，在线程达到 keep live 时间以后，可以自行销毁。


#### LinkedTransferQueue
LinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了tryTransfer和transfer方法。

LinkedTransferQueue(综合性的阻塞队列) 是一个高效阻塞无界链表队列。和 SynchronousQueue.TransferQueue (公平模式) 相比，它是可以统计长度，可以进行查询的；和 LinkedBlockingQueue 相比，它拥有更高的性能（使用 CAS 自旋）；和 ConcurrentLinkedQueue 相比，它拥有阻塞功能。貌似这个queue非常的全能，很多场景下都能够使用，是一个综合性的选手。综合性的选手，不容易在选型的时候被选择。（如果我们想要阻塞功能，我们会选真正的阻塞queue，专职专用；如果想要这种传球手的这种，我们可以选择syncQueue；如果想用非阻塞的queue，就用ConcurrentLinkedQueue ，专职专用。LinkedTransferQueue 就类似于一个本科大学；其他的queue是专科学院毕业，专精。）
LinkedTransferQueue目前使用场景比较多的情况是：我既想要使用传球手的这种便捷的功能，又有可能在queue里存储数据。
（1）transfer方法
如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者（syncqueue相似）。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。
（2）tryTransfer方法 （tryLock）
tryTransfer方法是用来试探生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法是必须等到消费者消费了才返回。

对于带有时间限制的tryTransfer（E e，long timeout，TimeUnit unit）方法，试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。


#### LinkedBlockingDeque
LinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。所谓双向队列指的是可以从队列的两端插入和移出元素（LinkedBlockingDeque产生的原因是什么？1.首先它是对LinkedBlockingQueue的一个补充，能支持双向存取； 2. 对阻塞队列的补充支持双向存取。）。

双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque多了addFirst、addLast、offerFirst、offerLast、peekFirst和peekLast等方法，以First单词结尾的方法，表示插入、获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入、获取或移除双端队列的最后一个元素。另外，插入方法add等同于addLast，移除方法remove等效于removeFirst。

在初始化LinkedBlockingDeque时可以设置容量防止其过度膨胀。另外，双向阻塞队列可以运用在“工作窃取”模式中。

1. 既然有双向队列，还那么方便，直接把单向队列移除?  功能越多，向 越多，Node节点越复杂，添加，移除越复杂；虽然是减小了竞争压力，但是对于一些不是很大竞争压力下的场景，我们的单向的队列还是非常好用的，如果竞争压力不大，而且也没必要从双端进行数据处理的场景下，用双向队列就适得其反了。

2. 双向队列的使用场景，一般是没有严格的顺序控制的场景使用。比如，我们将10个任务添加到双端队列，我们起两个线程进行任务处理（处理顺序无所谓，只要都处理完汇总即可），选择双端会减少竞争。

#### 什么是Fork/Join框架
Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务(compute方法)，最终汇总每个小任务结果后得到大任务结果的框架。

我们再通过Fork和Join这两个单词来理解一下Fork/Join框架。Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。比如计算1+2+…+10000，可以分割成10个子任务，每个子任务分别对1000个数进行求和，最终汇总这10个子任务的结果。Fork/Join的运行流程如图所示。

![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712210517.png)


#### 工作窃取算法
工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。那么，为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。比如A线程负责处理A队列里的任务。但是，有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。

![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712210629.png)

工作窃取算法的优点：充分利用线程进行并行计算，减少了线程间的竞争。工作窃取算法的缺点：并且该算法会消耗了更多的系统资源，比如创建多个线程和多个双端队列。



#### 使用Fork/Join框架
让我们通过一个简单的需求来使用Fork/Join框架，需求是：计算1+2+3+4的结果。

使用Fork/Join框架首先要考虑到的是如何分割任务，如果希望每个子任务最多执行两个数的相加，那么我们设置分割的阈值是2，由于是4个数字相加，所以Fork/Join框架会把这个任务fork成两个子任务，子任务一负责计算1+2，子任务二负责计算3+4，然后再join两个子任务的结果。

Fork/Join使用两个类来完成以上两件事情。

1. ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制。通常情况下，我们不需要直接继承ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了以下两个子类。

·RecursiveAction：用于没有返回结果的任务。
·RecursiveTask：用于有返回结果的任务。

2. ForkJoinPool：ForkJoinTask需要通过ForkJoinPool来执行。


### 线程池及Executor框架
#### 线程池的原理
1）线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。

2）线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。

3）线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712210902.png)
#### 线程池的原理
1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。
2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。
3）如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。
4）如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。

ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。
![](https://raw.githubusercontent.com/PANhuihuihuihui/PicBed/main/20220712210953.png)



### 线程池的参数
1）corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有基本线程。

2）runnableTaskQueue（任务队列）建议选用有界队列设置队列长度。1. 如果是无界队列，那么queue永远不会满，永远不会触发到maximumPoolSize，意味着maximumPoolSize这个参数就没有他的作用了； 2. 最重要的是无界队列无法控制队列最终包含的数据量，导致内存资源的极大的消耗甚至耗尽。3. 选用有界队列并合理的配置maximumPoolSize。4 饱和策略的使用根据需求选择。一旦我们触发了饱和策略，就说明：要么是我们的线程池配置有问题，要么真的是并发量太高，任务太多，导致的问题。警醒我们进行深入的参数调查及合理分配。

3）maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如果使用了无界的任务队列这个参数就没什么效果。

4）ThreadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。使用开源框架guava提供的ThreadFactoryBuilder可以快速给线程池里的线程设置有意义的名字
5）RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。在JDK 1.5中Java线程池框架提供了以下4种策略。

	AbortPolicy：直接抛出异常。相对多一些，因为我们会在异常处理的过程中进行各种手段：如果记录日志，存入数据库等待retry。。。
	CallerRunsPolicy：只用调用者所在线程来运行任务。用的也相对少一些。调用者线程也是系统资源，说明线程数量已经很多了，调用者线程的加入其实是变相增加了 maxsize
	DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。几乎没有人使用。
	DiscardPolicy：不处理，丢弃掉。 这种使用的也少
	当然，也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。（最推荐）

6）keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。所以，如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。

7）TimeUnit（线程活动保持时间的单位）：可选的单位有天（DAYS）、小时（HOURS）、分钟（MINUTES）、毫秒（MILLISECONDS）、微秒（MICROSECONDS，千分之一毫秒）和纳秒（NANOSECONDS，千分之一微秒）。


#### 如何合理配置线程池
要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析。
·任务的性质：CPU密集型任务、IO密集型任务和混合型任务。
·任务的优先级：高、中和低。
·任务的执行时间：长、中和短。
·任务的依赖性：是否依赖其他系统资源，如数据库连接。（我的线程池是 20 coresize，但是数据库同时只支持10个链接，这个时候要选择不能够大于数据库的连接数的一个数字，最大选10. maxsize也是 10. ）

性质不同的任务可以用不同规模的线程池分开处理。CPU密集型任务应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如2*Ncpu。

建议使用有界队列。有界队列能增加系统的稳定性和预警能力。
1. 如果没有看过那个视频的小伙伴，可以去看看b站的视频，说的很详细。
2. 我们的线程池是生存在一个复杂的系统环境里，我们还有其他的接口需要使用我们的服务器资源，所以在进行线程池coresize的配置以及maxsize的配置的时候，我们需要明确我们当前的接口的重要性，如果当前接口占据了未来业务访问的50%，那么就可以分配50%的系统资源给当前接口。（我们一个服务，总有一些重要接口和非重要接口，在我们进行项目开发初期，需求就定好了。）
3. 一定要基于压测。来评估线程池的参数是否合理。（全服务压测。）
4. 我们要给线程池开后门，可以动态的调整线程池的参数。（我们现在很多大型项目都有自己的配置中心，appolo是一个非常好的配置组件，你可以将coresize和maxsize配置到配置中心，一旦发生不可控的高并发场景，可以随时修改配置中心的参数，我们的项目就会按照新的标准进行调整。）

如果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，在监控线程池的时候可以使用以下属性。
·taskCount：线程池需要执行的任务数量。
·completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。
·largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。
·getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销毁，所以这个大小只增不减。
·getActiveCount：获取活动的线程数。
通过扩展线程池进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。例如，监控任务的平均执行时间、最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。

关闭线程池：
可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。


#### 线程池的监控及关闭
如果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，在监控线程池的时候可以使用以下属性。
·taskCount：线程池需要执行的任务数量。

·completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。

·largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。

·getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销毁，所以这个大小只增不减。

·getActiveCount：获取活动的线程数。

通过扩展线程池进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和线程池关闭前执行一些代码来进行监控。例如，监控任务的平均执行时间、最大执行时间和最小执行时间等。这几个方法在线程池里是空方法。

关闭线程池：

可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。